{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b4447f4",
   "metadata": {},
   "source": [
    "使用資料增強技術搭配正則化(regularization)技術，例如:early stopping, Bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fde0cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 類別對應： ['men', 'women']\n",
      " 訓練筆數（原始）： 220\n",
      " 測試筆數： 80\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Version A：原始資料（無增強）\n",
    "raw_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Version B：訓練用資料增強\n",
    "aug_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std =[0.229, 0.224, 0.225]),\n",
    "    transforms.RandomErasing(p=0.3,\n",
    "                             scale=(0.02, 0.15),\n",
    "                             ratio=(0.3, 3.3),\n",
    "                             value=0)  # 或用 'random'\n",
    "])\n",
    "\n",
    "# 載入訓練／測試 Dataset\n",
    "raw_train_full = datasets.ImageFolder(root=\"./data/train\", transform=raw_transform)\n",
    "raw_test     = datasets.ImageFolder(root=\"./data/test\",  transform=raw_transform)\n",
    "\n",
    "aug_train_full = datasets.ImageFolder(root=\"./data/train\", transform=aug_transform)\n",
    "#raw_transform 以評估增強後模型真實表現\n",
    "aug_val_full  = datasets.ImageFolder(root=\"./data/train\", transform=raw_transform)\n",
    "aug_test      = datasets.ImageFolder(root=\"./data/test\",  transform=raw_transform)\n",
    "\n",
    "print(\" 類別對應：\", raw_train_full.classes)\n",
    "print(\" 訓練筆數（原始）：\", len(raw_train_full))\n",
    "print(\" 測試筆數：\", len(raw_test))\n",
    "\n",
    "# 切分訓練 / 驗證集（8:2）\n",
    "train_ratio = 0.8\n",
    "raw_train_size = int(len(raw_train_full) * train_ratio)\n",
    "raw_val_size   = len(raw_train_full) - raw_train_size\n",
    "raw_train, raw_val = random_split(raw_train_full, [raw_train_size, raw_val_size])\n",
    "\n",
    "aug_train_size = int(len(aug_train_full) * train_ratio)\n",
    "aug_val_size   = len(aug_train_full) - aug_train_size\n",
    "aug_train, _   = random_split(aug_train_full, [aug_train_size, len(aug_train_full)-aug_train_size])\n",
    "_, aug_val     = random_split(aug_val_full, [aug_train_size, len(aug_val_full)-aug_train_size])\n",
    "\n",
    "# DataLoader\n",
    "batch_size = 64\n",
    "raw_train_loader = DataLoader(raw_train, batch_size=batch_size, shuffle=True)\n",
    "raw_val_loader   = DataLoader(raw_val,   batch_size=batch_size, shuffle=False)\n",
    "raw_test_loader  = DataLoader(raw_test,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "aug_train_loader = DataLoader(aug_train, batch_size=batch_size, shuffle=True)\n",
    "aug_val_loader   = DataLoader(aug_val,   batch_size=batch_size, shuffle=False)\n",
    "aug_test_loader  = DataLoader(aug_test,  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436dec99",
   "metadata": {},
   "source": [
    "Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b886076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs, device, patience, label=''):\n",
    "   \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "    best_acc = 0.0\n",
    "    best_state = copy.deepcopy(model.state_dict())\n",
    "    no_improve = 0\n",
    "\n",
    "    print(f\"開始訓練 with EarlyStopping(patience={patience}): {label}\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # --- Train ---\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)               # forward 只回傳 logits\n",
    "            loss = criterion(outputs, labels)     # 只用 CE Loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "        train_acc = 100 * correct / total\n",
    "\n",
    "        # --- Validate ---\n",
    "        model.eval()\n",
    "        val_correct, val_total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                val_correct += (preds == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "\n",
    "        print(\n",
    "            f\"[{label}] Epoch {epoch}/{num_epochs}  \"\n",
    "            f\"Loss: {running_loss:.4f}  \"\n",
    "            f\"Train Acc: {train_acc:.2f}%  Val Acc: {val_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "        # --- Early Stopping Check ---\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve >= patience:\n",
    "                print(f\"Early stopping triggered (no improvement for {patience} epochs).\")\n",
    "                break\n",
    "\n",
    "    # 載入最佳權重\n",
    "    model.load_state_dict(best_state)\n",
    "    print(f\"[{label}] 最佳驗證準確率: {best_acc:.2f}%\")\n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17f7bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, label=\"\"):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    print(f\"[{label}]  測試集準確率：{acc:.2f}%\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cda469f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class GenderCNN_Dropout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 載入預訓練 EfficientNet‑B0\n",
    "        self.backbone = models.efficientnet_b0(pretrained=True)\n",
    "        # 冻结大部分層，只解凍最後五個 block\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.backbone.features[-5:].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # 替換分類頭：純線性 + ReLU\n",
    "        self.backbone.classifier[1] = nn.Sequential(\n",
    "            nn.Linear(1280, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(256, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f4df23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Training Raw Model ==============================\n",
      "開始訓練 with EarlyStopping(patience=7): raw\n",
      "[raw] Epoch 1/20  Loss: 2.0637  Train Acc: 56.82%  Val Acc: 72.73%\n",
      "[raw] Epoch 2/20  Loss: 1.9378  Train Acc: 94.32%  Val Acc: 88.64%\n",
      "[raw] Epoch 3/20  Loss: 1.8004  Train Acc: 96.02%  Val Acc: 93.18%\n",
      "[raw] Epoch 4/20  Loss: 1.6743  Train Acc: 97.16%  Val Acc: 90.91%\n",
      "[raw] Epoch 5/20  Loss: 1.5659  Train Acc: 97.16%  Val Acc: 90.91%\n",
      "[raw] Epoch 6/20  Loss: 1.4752  Train Acc: 97.73%  Val Acc: 90.91%\n",
      "[raw] Epoch 7/20  Loss: 1.3997  Train Acc: 97.73%  Val Acc: 90.91%\n",
      "[raw] Epoch 8/20  Loss: 1.3632  Train Acc: 97.16%  Val Acc: 90.91%\n",
      "[raw] Epoch 9/20  Loss: 1.3219  Train Acc: 97.73%  Val Acc: 90.91%\n",
      "[raw] Epoch 10/20  Loss: 1.3333  Train Acc: 96.59%  Val Acc: 90.91%\n",
      "Early stopping triggered (no improvement for 7 epochs).\n",
      "[raw] 最佳驗證準確率: 93.18%\n",
      "\n",
      "============================== Training Augmented Model ==============================\n",
      "開始訓練 with EarlyStopping(patience=7): augmented\n",
      "[augmented] Epoch 1/20  Loss: 2.0707  Train Acc: 52.27%  Val Acc: 75.00%\n",
      "[augmented] Epoch 2/20  Loss: 1.9707  Train Acc: 76.14%  Val Acc: 81.82%\n",
      "[augmented] Epoch 3/20  Loss: 1.8789  Train Acc: 84.09%  Val Acc: 86.36%\n",
      "[augmented] Epoch 4/20  Loss: 1.7677  Train Acc: 89.20%  Val Acc: 88.64%\n",
      "[augmented] Epoch 5/20  Loss: 1.6796  Train Acc: 89.20%  Val Acc: 88.64%\n",
      "[augmented] Epoch 6/20  Loss: 1.5895  Train Acc: 90.91%  Val Acc: 90.91%\n",
      "[augmented] Epoch 7/20  Loss: 1.5644  Train Acc: 92.61%  Val Acc: 90.91%\n",
      "[augmented] Epoch 8/20  Loss: 1.5039  Train Acc: 92.61%  Val Acc: 90.91%\n",
      "[augmented] Epoch 9/20  Loss: 1.4720  Train Acc: 94.32%  Val Acc: 90.91%\n",
      "[augmented] Epoch 10/20  Loss: 1.4670  Train Acc: 93.18%  Val Acc: 90.91%\n",
      "[augmented] Epoch 11/20  Loss: 1.4666  Train Acc: 93.18%  Val Acc: 90.91%\n",
      "[augmented] Epoch 12/20  Loss: 1.4657  Train Acc: 92.05%  Val Acc: 90.91%\n",
      "[augmented] Epoch 13/20  Loss: 1.4384  Train Acc: 94.32%  Val Acc: 90.91%\n",
      "Early stopping triggered (no improvement for 7 epochs).\n",
      "[augmented] 最佳驗證準確率: 90.91%\n"
     ]
    }
   ],
   "source": [
    "# 訓練參數\n",
    "num_epochs = 20\n",
    "patience   = 7  \n",
    "model_raw = GenderCNN_Dropout().to(device)\n",
    "print(\"\\n\" + \"=\"*30 + \" Training Raw Model \" + \"=\"*30)\n",
    "model_raw = train_model(model_raw, raw_train_loader, raw_val_loader, num_epochs, device, patience, label=\"raw\")\n",
    "\n",
    "model_aug = GenderCNN_Dropout().to(device)\n",
    "print(\"\\n\" + \"=\"*30 + \" Training Augmented Model \" + \"=\"*30)\n",
    "model_aug = train_model(model_aug, aug_train_loader, aug_val_loader, num_epochs, device, patience, label=\"augmented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6647686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[raw]  測試集準確率：77.50%\n",
      "[augmented]  測試集準確率：78.75%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "78.75"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model_raw, raw_test_loader, device, label=\"raw\")\n",
    "evaluate_model(model_aug, aug_test_loader, device, label=\"augmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c530b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eb201\\miniconda3\\envs\\ML_env\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\eb201\\miniconda3\\envs\\ML_env\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== Bagging Model 1/5 ==========\n",
      "開始訓練 with EarlyStopping(patience=7): raw#1\n",
      "[raw#1] Epoch 1/20  Loss: 2.0686  Train Acc: 52.60%  Val Acc: 61.36%\n",
      "[raw#1] Epoch 2/20  Loss: 1.9022  Train Acc: 77.92%  Val Acc: 77.27%\n",
      "[raw#1] Epoch 3/20  Loss: 1.7461  Train Acc: 90.26%  Val Acc: 79.55%\n",
      "[raw#1] Epoch 4/20  Loss: 1.6010  Train Acc: 94.81%  Val Acc: 84.09%\n",
      "[raw#1] Epoch 5/20  Loss: 1.5003  Train Acc: 95.45%  Val Acc: 84.09%\n",
      "[raw#1] Epoch 6/20  Loss: 1.4009  Train Acc: 97.40%  Val Acc: 84.09%\n",
      "[raw#1] Epoch 7/20  Loss: 1.3835  Train Acc: 96.10%  Val Acc: 84.09%\n",
      "[raw#1] Epoch 8/20  Loss: 1.3114  Train Acc: 97.40%  Val Acc: 81.82%\n",
      "[raw#1] Epoch 9/20  Loss: 1.3092  Train Acc: 96.75%  Val Acc: 84.09%\n",
      "[raw#1] Epoch 10/20  Loss: 1.2558  Train Acc: 96.75%  Val Acc: 86.36%\n",
      "[raw#1] Epoch 11/20  Loss: 1.2348  Train Acc: 98.05%  Val Acc: 86.36%\n",
      "[raw#1] Epoch 12/20  Loss: 1.2182  Train Acc: 97.40%  Val Acc: 86.36%\n",
      "[raw#1] Epoch 13/20  Loss: 1.2183  Train Acc: 99.35%  Val Acc: 86.36%\n",
      "[raw#1] Epoch 14/20  Loss: 1.2269  Train Acc: 98.05%  Val Acc: 86.36%\n",
      "[raw#1] Epoch 15/20  Loss: 1.2217  Train Acc: 97.40%  Val Acc: 88.64%\n",
      "[raw#1] Epoch 16/20  Loss: 1.2164  Train Acc: 98.05%  Val Acc: 88.64%\n",
      "[raw#1] Epoch 17/20  Loss: 1.2049  Train Acc: 98.70%  Val Acc: 88.64%\n",
      "[raw#1] Epoch 18/20  Loss: 1.2274  Train Acc: 97.40%  Val Acc: 88.64%\n",
      "[raw#1] Epoch 19/20  Loss: 1.1812  Train Acc: 99.35%  Val Acc: 88.64%\n",
      "[raw#1] Epoch 20/20  Loss: 1.2097  Train Acc: 97.40%  Val Acc: 88.64%\n",
      "[raw#1] 最佳驗證準確率: 88.64%\n",
      "\n",
      "========== Bagging Model 2/5 ==========\n",
      "開始訓練 with EarlyStopping(patience=7): raw#2\n",
      "[raw#2] Epoch 1/20  Loss: 2.0567  Train Acc: 53.25%  Val Acc: 56.82%\n",
      "[raw#2] Epoch 2/20  Loss: 1.8930  Train Acc: 76.62%  Val Acc: 75.00%\n",
      "[raw#2] Epoch 3/20  Loss: 1.7290  Train Acc: 85.71%  Val Acc: 77.27%\n",
      "[raw#2] Epoch 4/20  Loss: 1.6179  Train Acc: 88.31%  Val Acc: 81.82%\n",
      "[raw#2] Epoch 5/20  Loss: 1.4348  Train Acc: 92.86%  Val Acc: 88.64%\n",
      "[raw#2] Epoch 6/20  Loss: 1.3874  Train Acc: 93.51%  Val Acc: 86.36%\n",
      "[raw#2] Epoch 7/20  Loss: 1.3193  Train Acc: 94.81%  Val Acc: 84.09%\n",
      "[raw#2] Epoch 8/20  Loss: 1.2551  Train Acc: 96.10%  Val Acc: 84.09%\n",
      "[raw#2] Epoch 9/20  Loss: 1.2342  Train Acc: 97.40%  Val Acc: 84.09%\n",
      "[raw#2] Epoch 10/20  Loss: 1.1993  Train Acc: 95.45%  Val Acc: 84.09%\n",
      "[raw#2] Epoch 11/20  Loss: 1.2335  Train Acc: 94.81%  Val Acc: 86.36%\n",
      "[raw#2] Epoch 12/20  Loss: 1.1890  Train Acc: 96.10%  Val Acc: 86.36%\n",
      "Early stopping triggered (no improvement for 7 epochs).\n",
      "[raw#2] 最佳驗證準確率: 88.64%\n",
      "\n",
      "========== Bagging Model 3/5 ==========\n",
      "開始訓練 with EarlyStopping(patience=7): raw#3\n",
      "[raw#3] Epoch 1/20  Loss: 2.0582  Train Acc: 57.14%  Val Acc: 75.00%\n",
      "[raw#3] Epoch 2/20  Loss: 1.8795  Train Acc: 94.16%  Val Acc: 93.18%\n",
      "[raw#3] Epoch 3/20  Loss: 1.6916  Train Acc: 96.75%  Val Acc: 88.64%\n",
      "[raw#3] Epoch 4/20  Loss: 1.5410  Train Acc: 96.75%  Val Acc: 84.09%\n",
      "[raw#3] Epoch 5/20  Loss: 1.3997  Train Acc: 98.05%  Val Acc: 84.09%\n",
      "[raw#3] Epoch 6/20  Loss: 1.3379  Train Acc: 96.10%  Val Acc: 84.09%\n",
      "[raw#3] Epoch 7/20  Loss: 1.2808  Train Acc: 96.75%  Val Acc: 86.36%\n",
      "[raw#3] Epoch 8/20  Loss: 1.2140  Train Acc: 97.40%  Val Acc: 88.64%\n",
      "[raw#3] Epoch 9/20  Loss: 1.2166  Train Acc: 98.05%  Val Acc: 88.64%\n",
      "Early stopping triggered (no improvement for 7 epochs).\n",
      "[raw#3] 最佳驗證準確率: 93.18%\n",
      "\n",
      "========== Bagging Model 4/5 ==========\n",
      "開始訓練 with EarlyStopping(patience=7): raw#4\n",
      "[raw#4] Epoch 1/20  Loss: 2.0478  Train Acc: 64.94%  Val Acc: 54.55%\n",
      "[raw#4] Epoch 2/20  Loss: 1.8772  Train Acc: 74.03%  Val Acc: 59.09%\n",
      "[raw#4] Epoch 3/20  Loss: 1.6514  Train Acc: 77.27%  Val Acc: 61.36%\n",
      "[raw#4] Epoch 4/20  Loss: 1.5358  Train Acc: 86.36%  Val Acc: 68.18%\n",
      "[raw#4] Epoch 5/20  Loss: 1.4152  Train Acc: 85.71%  Val Acc: 70.45%\n",
      "[raw#4] Epoch 6/20  Loss: 1.2732  Train Acc: 90.91%  Val Acc: 70.45%\n",
      "[raw#4] Epoch 7/20  Loss: 1.2407  Train Acc: 91.56%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 8/20  Loss: 1.2409  Train Acc: 92.21%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 9/20  Loss: 1.1854  Train Acc: 95.45%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 10/20  Loss: 1.1526  Train Acc: 94.16%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 11/20  Loss: 1.1905  Train Acc: 92.86%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 12/20  Loss: 1.1434  Train Acc: 94.16%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 13/20  Loss: 1.1537  Train Acc: 95.45%  Val Acc: 75.00%\n",
      "[raw#4] Epoch 14/20  Loss: 1.1650  Train Acc: 92.21%  Val Acc: 75.00%\n",
      "Early stopping triggered (no improvement for 7 epochs).\n",
      "[raw#4] 最佳驗證準確率: 75.00%\n",
      "\n",
      "========== Bagging Model 5/5 ==========\n",
      "開始訓練 with EarlyStopping(patience=7): raw#5\n",
      "[raw#5] Epoch 1/20  Loss: 2.0657  Train Acc: 55.84%  Val Acc: 84.09%\n",
      "[raw#5] Epoch 2/20  Loss: 1.9074  Train Acc: 98.05%  Val Acc: 88.64%\n",
      "[raw#5] Epoch 3/20  Loss: 1.7413  Train Acc: 98.05%  Val Acc: 90.91%\n",
      "[raw#5] Epoch 4/20  Loss: 1.5981  Train Acc: 99.35%  Val Acc: 88.64%\n",
      "[raw#5] Epoch 5/20  Loss: 1.4844  Train Acc: 99.35%  Val Acc: 90.91%\n",
      "[raw#5] Epoch 6/20  Loss: 1.3768  Train Acc: 99.35%  Val Acc: 93.18%\n",
      "[raw#5] Epoch 7/20  Loss: 1.3129  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 8/20  Loss: 1.2388  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 9/20  Loss: 1.2304  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 10/20  Loss: 1.2128  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 11/20  Loss: 1.1867  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 12/20  Loss: 1.1823  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 13/20  Loss: 1.1750  Train Acc: 99.35%  Val Acc: 97.73%\n",
      "[raw#5] Epoch 14/20  Loss: 1.2012  Train Acc: 100.00%  Val Acc: 97.73%\n",
      "Early stopping triggered (no improvement for 7 epochs).\n",
      "[raw#5] 最佳驗證準確率: 97.73%\n",
      "\n",
      "Bagging Ensemble Test Acc: 76.25%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "\n",
    "def train_bagging_ensemble(base_model_cls, train_dataset, val_loader, test_loader, n_estimators=5, bootstrap_ratio=1.0, num_epochs=20, device=torch.device(\"cpu\"), patience=5, label_prefix=''):\n",
    "\n",
    "    all_models = []\n",
    "    batch_size = val_loader.batch_size\n",
    "\n",
    "    # 1. 訓練每個基學習器\n",
    "    for i in range(n_estimators):\n",
    "        # 1.1 Bootstrap sample\n",
    "        n_samples = int(len(train_dataset) * bootstrap_ratio)\n",
    "        indices = [random.randrange(len(train_dataset)) for _ in range(n_samples)]\n",
    "        sampler = SubsetRandomSampler(indices)\n",
    "        loader = DataLoader(train_dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "        # 1.2 建立並訓練模型\n",
    "        model = base_model_cls().to(device)\n",
    "        print(f\"\\n{'='*10} Bagging Model {i+1}/{n_estimators} {'='*10}\")\n",
    "        model = train_model(model, loader, val_loader, num_epochs, device, patience=patience, label=f\"{label_prefix}#{i+1}\")\n",
    "        all_models.append(copy.deepcopy(model))\n",
    "\n",
    "    # 2. 在測試集上做軟投票（平均 logits → argmax）\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # 收集每個基學習器的 logits\n",
    "        logits_stack = torch.stack([m(images) for m in all_models], dim=0)\n",
    "        avg_logits = logits_stack.mean(dim=0)\n",
    "        preds = avg_logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    test_acc = 100 * correct / total\n",
    "    print(f\"\\nBagging Ensemble Test Acc: {test_acc:.2f}%\")\n",
    "    return all_models, test_acc\n",
    "\n",
    "# 使用範例\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "# 假設 raw_transform 已定義\n",
    "train_dataset = datasets.ImageFolder(root=\"./data/train\", transform=raw_transform)\n",
    "\n",
    "models, ensemble_acc = train_bagging_ensemble(\n",
    "    base_model_cls=GenderCNN_Dropout,       \n",
    "    train_dataset=train_dataset,\n",
    "    val_loader=raw_val_loader,\n",
    "    test_loader=raw_test_loader,\n",
    "    n_estimators=5,\n",
    "    bootstrap_ratio=0.7,\n",
    "    num_epochs=20,\n",
    "    device=device,\n",
    "    patience=7,\n",
    "    label_prefix='raw'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fd147b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1 Test Acc: 73.75%\n",
      "Model #2 Test Acc: 73.75%\n",
      "Model #3 Test Acc: 80.00%\n",
      "Model #4 Test Acc: 62.50%\n",
      "Model #5 Test Acc: 80.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "def evaluate_individual_models(models, test_loader, device):\n",
    "    \n",
    "    accuracies = []\n",
    "    for i, model in enumerate(models, start=1):\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)           # logits\n",
    "                preds = outputs.argmax(dim=1)\n",
    "                correct += (preds == labels).sum().item()\n",
    "                total += labels.size(0)\n",
    "        acc = correct / total * 100\n",
    "        accuracies.append(acc)\n",
    "        print(f\"Model #{i} Test Acc: {acc:.2f}%\")\n",
    "    return accuracies\n",
    "\n",
    "# 1. 個別基學習器\n",
    "individual_accuracies = evaluate_individual_models(models, raw_test_loader, device)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
